{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this notebook - it just collects code shared between notebooks 1+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import re\n",
    "\n",
    "from __future__ import print_function\n",
    "from math import log, pow\n",
    "from collections import Counter\n",
    "\n",
    "lanl_path = \"/Users/etc/data/LANL/\"\n",
    "\n",
    "dnsfile = lanl_path + \"dns.txt\"\n",
    "flowfile = lanl_path + \"flows.txt\"\n",
    "procfile = lanl_path + \"proc.txt\"\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# section 2: aligning timestamps\n",
    "\n",
    "\"\"\"\n",
    "x = proc\n",
    "y = flow\n",
    "z = dns\n",
    "\n",
    "y - x = -20 * 60\n",
    "z - y =  80 * 60\n",
    "x - z = -60 * 60 \n",
    "\n",
    "==> \n",
    "\"\"\"\n",
    "\n",
    "flow_offset = -20 * 60\n",
    "dns_offset = 60 * 60\n",
    "proc_offset = 0\n",
    "\n",
    "def flow_parser(x): return  [int(x[0]) - flow_offset, int(x[1])] \\\n",
    "                + [str(x[i]) for i in range(2,6)] \\\n",
    "                + [int(x[i]) for i in range(6,9)]\n",
    "\n",
    "def dns_parser(x): return [int(x[0]) - dns_offset]\\\n",
    "               + [str(x[i]) for i in range(1,len(x))]\n",
    "\n",
    "def proc_parser(x):\n",
    "    n = len(x)\n",
    "    return  [int(x[0])] + str(x[1]).split('@') + [str(x[i]) for i in range(2,n)]\n",
    "\n",
    "procs = sc.textFile(procfile)\\\n",
    "    .map(lambda line: proc_parser(line.split(',')))\n",
    "flows = sc.textFile(flowfile)\\\n",
    "    .map(lambda line: flow_parser(line.split(',')))\n",
    "dns = sc.textFile(dnsfile)\\\n",
    "    .map(lambda line: dns_parser(line.split(',')))\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# section 4: Process P265\n",
    "\n",
    "proc_p265 = procs.filter(lambda x: x[4] == 'P265').map(lambda x: x[0:4] + [x[5]])\n",
    "p265_comps = proc_p265\\\n",
    "            .filter(lambda x: x[4]=='Start')\\\n",
    "            .map(lambda x: (x[3], x[0]))\\\n",
    "            .groupByKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
